
# ğŸ“˜ DÃ©tection Visuelle AutomatisÃ©e â€” Documentation Technique

## ğŸ¯ Objectif du projet

DÃ©tecter automatiquement les **dommages** (fissures, trous, rayures) et **Ã©quipements** (prises, interrupteurs, extincteurs) dans les bÃ¢timents Ã  partir dâ€™**images** envoyÃ©es via une app **iOS**.

â¡ï¸ Le tout est analysÃ© par un **serveur Flask** utilisant le modÃ¨le **Qwen-VL**.

---

## ğŸ§± Architecture du projet

ğŸ“· *App iOS* â†’ ğŸ“¤ *Upload ZIP (image + calibration.json)* â†’ ğŸ” *Serveur Flask avec Qwen-VL* â†’ ğŸ–¼ *Image annotÃ©e + JSON des rÃ©sultats*

---

## ğŸ“‚ Structure du projet

```
aws_llmv_ios/
â”œâ”€â”€ app.py                  # Serveur Flask principal
â”œâ”€â”€ process_depth.py        # Traitement des images et interaction avec Qwen-VL
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html          # Interface web dâ€™upload
â”‚   â””â”€â”€ result2.html        # Page rÃ©sultat avec image annotÃ©e
â”œâ”€â”€ uploads/                # Fichiers reÃ§us
â”œâ”€â”€ output/                 # Images annotÃ©es
â””â”€â”€ requirements.txt        # DÃ©pendances
```

---

## âš™ï¸ Lancer le projet

### ğŸ“¥ 1. Installation

```bash
git clone https://github.com/votre-utilisateur/votre-repo.git
cd aws_llmv_ios
pip install -r requirements.txt
```

### ğŸš€ 2. Lancement local (dÃ©veloppement)

```bash
python app.py
```

### ğŸŒ 3. Serveur de production

```bash
nohup python app.py > flask.log 2>&1 &
```

### ğŸŒ 4. Exposition au rÃ©seau (Ngrok)

```bash
nohup ngrok http 5000 --log=stdout > ngrok.log 2>&1 &
```

Une URL publique sera gÃ©nÃ©rÃ©e pour lâ€™application iOS.

---

## ğŸ§  Fonctionnement du traitement (`process_depth.py`)

- DÃ©compression du `.zip`
- Lecture de `calibration.json`
- Analyse de lâ€™image avec Qwen-VL via prompts textuels
- Calcul des dimensions physiques (mm)
- Position du dommage dans lâ€™image
- GÃ©nÃ©ration image annotÃ©e + rÃ©ponse structurÃ©e

---

## ğŸ–¥ Interface Web

Accessible via `http://localhost:5000`

- Upload fichier `.zip`
- Choix entre "dommages" ou "Ã©quipements"
- RÃ©sultat affichÃ© avec :
  - Type dÃ©tectÃ©
  - Dimensions (mm)
  - Surface
  - Position
  - Image annotÃ©e

---

## ğŸ“² Fonctionnement de lâ€™app iOS

1. Prend une photo
2. CrÃ©e un `.zip` contenant `image.jpg` + `calibration.json`
3. Envoie automatique via `POST /upload_zip`
4. ReÃ§oit JSON avec dimensions, type, position, et image annotÃ©e

---

## ğŸ“¤ API REST

### Endpoint : `POST /upload_zip`

#### Contenu attendu : `.zip` avec image + calibration

#### RÃ©ponse exemple :

```json
{
  "damage_type": "hole",
  "width_mm": 13,
  "height_mm": 15,
  "surface_mm2": 195,
  "position": "au milieu au centre",
  "annotated_image_url": "http://.../output/image.jpg"
}
```

---

## ğŸ¤– ModÃ¨le Qwen-VL

ModÃ¨le vision/langage (transformer) utilisÃ© pour :
- Identifier objets/dommages
- Dessiner des boÃ®tes englobantes
- Retourner le type de dommage

Lâ€™interaction est faite via des **prompts textuels** gÃ©nÃ©rÃ©s dynamiquement.

---

## ğŸ“§ Auteur

Benouadah Alaeddine
